{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqjwWgBb0KuQ",
        "outputId": "ac267a52-532e-4c7b-cfc7-f17f56500410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sGp6nh6E0OkY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.image import resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hxUEWinA0OmW"
      },
      "outputs": [],
      "source": [
        "classes= ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n",
        "input_shape = (64, 64, 1) \n",
        "num_classes = 10          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wuPcmKdO0OqC"
      },
      "outputs": [],
      "source": [
        "class CNNModel:\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        stddev = 0.01  \n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.weights = {\n",
        "            'conv1': tf.Variable(tf.random.normal([3, 3, input_shape[-1], 32], stddev=stddev)),\n",
        "            'conv2': tf.Variable(tf.random.normal([3, 3, 32, 32], stddev=stddev)),\n",
        "            'conv3': tf.Variable(tf.random.normal([3, 3, 32, 64], stddev=stddev)),\n",
        "            'conv4': tf.Variable(tf.random.normal([3, 3, 64, 64], stddev=stddev)),\n",
        "            'conv5': tf.Variable(tf.random.normal([3, 3, 64, 128], stddev=stddev)),\n",
        "            'conv6': tf.Variable(tf.random.normal([3, 3, 128, 128], stddev=stddev)),\n",
        "\n",
        "            'fc1': None,\n",
        "            'fc2': tf.Variable(tf.random.normal([1200, num_classes], stddev=stddev))\n",
        "        }\n",
        "        self.biases = {\n",
        "            'conv1': tf.Variable(tf.zeros([32])),\n",
        "            'conv2': tf.Variable(tf.zeros([32])),\n",
        "            'conv3': tf.Variable(tf.zeros([64])),\n",
        "            'conv4': tf.Variable(tf.zeros([64])),\n",
        "            'conv5': tf.Variable(tf.zeros([128])),\n",
        "            'conv6': tf.Variable(tf.zeros([128])),\n",
        "            'fc1': None,\n",
        "            'fc2': tf.Variable(tf.zeros([num_classes]))\n",
        "        }\n",
        "\n",
        "    def build_fc1(self, x):\n",
        "        #dynamically calculate the flattened size\n",
        "        flatten_dim = np.prod(x.shape[1:])  # Total size after flattening\n",
        "        self.weights['fc1'] = tf.Variable(tf.random.normal([flatten_dim, 1200], stddev=0.01))\n",
        "        self.biases['fc1'] = tf.Variable(tf.zeros([1200]))\n",
        "\n",
        "    def forward(self, x, is_training=True):\n",
        "        #convolutional layers with ReLU, Max Pooling, and Dropout\n",
        "        x = tf.nn.conv2d(x, self.weights['conv1'], strides=1, padding='SAME') + self.biases['conv1']\n",
        "        x = tf.nn.relu(x)\n",
        "        x = tf.nn.conv2d(x, self.weights['conv2'], strides=1, padding='VALID') + self.biases['conv2']\n",
        "        x = tf.nn.relu(x)\n",
        "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
        "\n",
        "        x = tf.nn.conv2d(x, self.weights['conv3'], strides=1, padding='SAME') + self.biases['conv3']\n",
        "        x = tf.nn.relu(x)\n",
        "        x = tf.nn.conv2d(x, self.weights['conv4'], strides=1, padding='VALID') + self.biases['conv4']\n",
        "        x = tf.nn.relu(x)\n",
        "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
        "\n",
        "        x = tf.nn.conv2d(x, self.weights['conv5'], strides=1, padding='SAME') + self.biases['conv5']\n",
        "        x = tf.nn.relu(x)\n",
        "        x = tf.nn.conv2d(x, self.weights['conv6'], strides=1, padding='VALID') + self.biases['conv6']\n",
        "        x = tf.nn.relu(x)\n",
        "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n",
        "\n",
        "        if is_training:\n",
        "            x = tf.nn.dropout(x, rate=0.3)\n",
        "\n",
        "        #flatten\n",
        "        x = tf.reshape(x, [x.shape[0], -1])\n",
        "\n",
        "        #initialize fully connected layer weights if not already done\n",
        "        if self.weights['fc1'] is None:\n",
        "            self.build_fc1(x)\n",
        "\n",
        "        #fully connected layers\n",
        "        x = tf.matmul(x, self.weights['fc1']) + self.biases['fc1']\n",
        "        x = tf.nn.relu(x)\n",
        "\n",
        "        if is_training:\n",
        "            x = tf.nn.dropout(x, rate=0.4)\n",
        "\n",
        "        x = tf.matmul(x, self.weights['fc2']) + self.biases['fc2']\n",
        "        return x  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GQsPu4OA0OuN"
      },
      "outputs": [],
      "source": [
        "#initialize the model\n",
        "model = CNNModel(input_shape=input_shape, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NWtSOa1R0OyV"
      },
      "outputs": [],
      "source": [
        "save_dir = \"/content/drive/MyDrive/Colab Notebooks/model_backup_final/saved_model_final\"\n",
        "#forfuture use loading weights and biases\n",
        "def load_model_weights(model, save_dir):\n",
        "\n",
        "    for name, variable in model.weights.items():\n",
        "        model.weights[name] = tf.convert_to_tensor(np.load(os.path.join(save_dir, f\"{name}_weights.npy\")))\n",
        "    for name, variable in model.biases.items():\n",
        "        model.biases[name] = tf.convert_to_tensor(np.load(os.path.join(save_dir, f\"{name}_biases.npy\")))\n",
        "\n",
        "    for name, variable in model.weights.items():\n",
        "        print(f\"Loaded weight {name}: {variable.shape}\")\n",
        "    for name, variable in model.biases.items():\n",
        "        print(f\"Loaded bias {name}: {variable.shape}\")\n",
        "\n",
        "    # for name, weight in model.weights.items():\n",
        "    #     if weight is None:\n",
        "    #         print(f\"Weight '{name}' is not initialized. Skipping...\")\n",
        "    #         continue\n",
        "    #     weight_path = os.path.join(save_dir, f\"{name}_weights.npy\")\n",
        "    #     if os.path.exists(weight_path):\n",
        "    #         # Use assign to update weights\n",
        "    #         weight.assign(np.load(weight_path))\n",
        "    #         print(f\"Loaded weights for {name} from {weight_path}\")\n",
        "    #     else:\n",
        "    #         print(f\"Weight file not found for {name}: {weight_path}\")\n",
        "\n",
        "    # for name, bias in model.biases.items():\n",
        "    #     if bias is None:\n",
        "    #         print(f\"Bias '{name}' is not initialized. Skipping...\")\n",
        "    #         continue\n",
        "    #     bias_path = os.path.join(save_dir, f\"{name}_biases.npy\")\n",
        "    #     if os.path.exists(bias_path):\n",
        "    #         # Use assign to update biases\n",
        "    #         bias.assign(np.load(bias_path))\n",
        "    #         print(f\"Loaded biases for {name} from {bias_path}\")\n",
        "    #     else:\n",
        "    #         print(f\"Bias file not found for {name}: {bias_path}\")\n",
        "\n",
        "    print(\"Model weights and biases loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-2bd8fwj5gBj",
        "outputId": "85633427-f6fe-4877-e3f5-5e91f4ab98d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded weight conv1: (3, 3, 1, 32)\n",
            "Loaded weight conv2: (3, 3, 32, 32)\n",
            "Loaded weight conv3: (3, 3, 32, 64)\n",
            "Loaded weight conv4: (3, 3, 64, 64)\n",
            "Loaded weight conv5: (3, 3, 64, 128)\n",
            "Loaded weight conv6: (3, 3, 128, 128)\n",
            "Loaded weight fc1: (6272, 1200)\n",
            "Loaded weight fc2: (1200, 10)\n",
            "Loaded bias conv1: (32,)\n",
            "Loaded bias conv2: (32,)\n",
            "Loaded bias conv3: (64,)\n",
            "Loaded bias conv4: (64,)\n",
            "Loaded bias conv5: (128,)\n",
            "Loaded bias conv6: (128,)\n",
            "Loaded bias fc1: (1200,)\n",
            "Loaded bias fc2: (10,)\n",
            "Model weights and biases loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "load_model_weights(model, save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nzI10Orl0mYK"
      },
      "outputs": [],
      "source": [
        "#load and preprocess audio data\n",
        "def load_and_preprocess_file(file_path, target_shape=(64,64)):\n",
        "    data = []\n",
        "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
        "    # Perform preprocessing (e.g., convert to Mel spectrogram and resize)\n",
        "    # Define the duration of each chunk and overlap\n",
        "    chunk_duration = 4  # seconds\n",
        "    overlap_duration = 2  # seconds\n",
        "\n",
        "    #convert durations to samples\n",
        "    chunk_samples = chunk_duration * sample_rate\n",
        "    overlap_samples = overlap_duration * sample_rate\n",
        "\n",
        "    #calculate the number of chunks\n",
        "    num_chunks = int(np.ceil((len(audio_data) - chunk_samples) / (chunk_samples - overlap_samples))) + 1\n",
        "\n",
        "    #iterate over each chunk\n",
        "    for i in range(num_chunks):\n",
        "        start = i * (chunk_samples - overlap_samples)\n",
        "        end = start + chunk_samples\n",
        "\n",
        "        chunk = audio_data[start:end]\n",
        "\n",
        "       #compute the Mel spectrogram for the chunk\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=chunk, sr=sample_rate)\n",
        "        mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), target_shape)\n",
        "        data.append(mel_spectrogram)\n",
        "\n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97mU9OZbE8dg",
        "outputId": "dd776d84-4752-4438-ce84-0de61d65ea92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test output shape: (1, 10)\n"
          ]
        }
      ],
      "source": [
        "test_input = np.random.rand(1, *input_shape).astype(np.float32)\n",
        "test_output = model.forward(test_input, is_training=False)\n",
        "print(f\"Test output shape: {test_output.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nee768ck0mam"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/test_music/reggae.00004.wav\"\n",
        "X_test=load_and_preprocess_file(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq5aCqc-F2y5",
        "outputId": "cbe996d2-0008-4c9f-ad74-8bf97c8d4487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15, 64, 64, 1)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "T2RsgHfc0wRa"
      },
      "outputs": [],
      "source": [
        "def model_prediction(model, X_test):\n",
        "    #to forward pass through the model\n",
        "    logits = model.forward(X_test, is_training=False)\n",
        "\n",
        "    #then coompute probabilities using softmax\n",
        "    probabilities = tf.nn.softmax(logits, axis=1).numpy()\n",
        "\n",
        "    #to predict categories (argmax of probabilities)\n",
        "    predicted_categories = np.argmax(probabilities, axis=1)\n",
        "\n",
        "    #to get unique elements and their counts\n",
        "    unique_elements, counts = np.unique(predicted_categories, return_counts=True)\n",
        "\n",
        "    #this dtermine the most frequent predicted category\n",
        "    max_count = np.max(counts)\n",
        "    max_elements = unique_elements[counts == max_count]\n",
        "\n",
        "    return max_elements[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ewlxCi_0wTZ",
        "outputId": "cfd2b71c-598f-4679-d09e-190265a5cd5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The predicted genre is: 8 reggae\n"
          ]
        }
      ],
      "source": [
        "predicted_genre = model_prediction(model, X_test)\n",
        "print(f\"The predicted genre is: {predicted_genre}\",classes[predicted_genre])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp5XvoAu0wXZ",
        "outputId": "c57ef6e8-3cce-47d4-f47b-55e52336330b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model input shape: (64, 64, 1)\n",
            "Number of classes: 10\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model input shape: {input_shape}\")\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0iN89yTGKBu",
        "outputId": "60bd3cb5-9131-4e22-a867-1e8006615c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight conv1: (3, 3, 1, 32)\n",
            "Weight conv2: (3, 3, 32, 32)\n",
            "Weight conv3: (3, 3, 32, 64)\n",
            "Weight conv4: (3, 3, 64, 64)\n",
            "Weight conv5: (3, 3, 64, 128)\n",
            "Weight conv6: (3, 3, 128, 128)\n",
            "Weight fc1: (6272, 1200)\n",
            "Weight fc2: (1200, 10)\n",
            "Bias conv1: (32,)\n",
            "Bias conv2: (32,)\n",
            "Bias conv3: (64,)\n",
            "Bias conv4: (64,)\n",
            "Bias conv5: (128,)\n",
            "Bias conv6: (128,)\n",
            "Bias fc1: (1200,)\n",
            "Bias fc2: (10,)\n"
          ]
        }
      ],
      "source": [
        "for name, variable in model.weights.items():\n",
        "    print(f\"Weight {name}: {variable.numpy().shape}\")\n",
        "for name, variable in model.biases.items():\n",
        "    print(f\"Bias {name}: {variable.numpy().shape}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
